# /configs/test.yaml

# Modular testing: swap task, model, and dataset just like training
defaults:
  - _self_
  - task: recon                 # override on CLI if you test another task
  - model: AutoEncoder3D        # override on CLI: model=<another>
  - datamodule: ae              # override on CLI: datamodule=<another>

seed: 42

# Path to the checkpoint you want to evaluate (override from CLI)
ckpt_path: null                 # e.g., ckpt_path=/path/to/best.ckpt

# Optional logger (same structure as train)
logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: logs
  name: ${hydra:runtime.choices.task}-${hydra:runtime.choices.model}/test

# Reuse the same pattern as train to instantiate from the group configs
datamodule: ${datamodule.module}
model: ${model.module}

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: auto
  devices: 1
  precision: 16-mixed           # match training if you trained in mixed precision
  log_every_n_steps: 10
